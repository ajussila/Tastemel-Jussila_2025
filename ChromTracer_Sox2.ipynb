{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author__: Bogdan Bintu, Modified by Adam Jussila\n",
    "\n",
    "__Date__: 01/28/2025\n",
    "\n",
    "__Scope__: Analysis tool Ren Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pipeline setup</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline requires the following additional packages to be installed in the python environment: pytorch, py-opencv\n",
    "\n",
    "These can be installed with this command in the anaconda prompt:\n",
    "\n",
    "`conda install pytorch py-opencv`\n",
    "\n",
    "The environment all data analyzed in this manuscript were run with is attached using the environment_ChromTracer_Sox2.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Set the folder with the raw data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_folders = [r'/path/to/raw/data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Set the folder for the analysis results</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_folder = r'/path/to/analysis/folder'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Specify colors used in this experiment</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['750','647', '561', 'beads']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Initialize the pipeline</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "\n",
    "sys.path.append(r'/path/to/CommonTools')\n",
    "import DomainTools as dt\n",
    "\n",
    "import PipelineFunctions as pipeline\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.spatial.distance import squareform,pdist,cdist\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "experiment_name, em_threshold = pipeline.load_params(analysis_folder)\n",
    "\n",
    "folders, fovs, h0_folder = pipeline.load_data(master_folders, analysis_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import IOTools as io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Nuclei segmentation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Pattern matching all DAX files to segment\n",
    "dax_files = master_folders[0]+os.sep+r\"H0B,B,B\\Conv_zscan_*.dax\"\n",
    "save_dir = analysis_folder+os.sep+r\"segmentation\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "#How many channels are in the dax files\n",
    "dax_channels = 5\n",
    "#Which channel to use for segmentation (counts from 0)\n",
    "channel = 4\n",
    "#Which z-slice to use for segmentation (counts from 0)\n",
    "zslice = 15\n",
    "###\n",
    "\n",
    "import glob\n",
    "\n",
    "files = list(sorted([f for f in glob.glob(dax_files)]))\n",
    "print(f\"Found {len(files)} files to segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from daxfile import DaxFile\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "print(\"Loading images\")\n",
    "imgs = [DaxFile(filename, num_channels=dax_channels).zslice(zslice, channel) for filename in tqdm(files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "for k,img in enumerate(imgs[0:3]):\n",
    "    plt.subplot(1,3,k+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, vmax=np.percentile(img, 99), cmap='gray')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RUN CELLPOSE\n",
    "import os\n",
    "from cellpose import models, io\n",
    "from skimage.segmentation import expand_labels\n",
    "\n",
    "# DEFINE CELLPOSE MODEL\n",
    "# model_type='cyto' or model_type='nuclei'\n",
    "model = models.Cellpose(gpu=False, model_type='nuclei')\n",
    "\n",
    "# define CHANNELS to run segementation on\n",
    "# grayscale=0, R=1, G=2, B=3\n",
    "# channels = [cytoplasm, nucleus]\n",
    "# if NUCLEUS channel does not exist, set the second channel to 0\n",
    "channels = [0,0]\n",
    "# IF ALL YOUR IMAGES ARE THE SAME TYPE, you can give a list with 2 elements\n",
    "# channels = [0,0] # IF YOU HAVE GRAYSCALE\n",
    "# channels = [2,3] # IF YOU HAVE G=cytoplasm and B=nucleus \n",
    "# channels = [2,1] # IF YOU HAVE G=cytoplasm and R=nucleus\n",
    "#channels = [2,3]\n",
    "\n",
    "# or if you have different types of channels in each image\n",
    "#channels = [[2,3], [0,0], [0,0]]\n",
    "\n",
    "# if diameter is set to None, the size of the cells is estimated on a per image basis\n",
    "# you can set the average cell `diameter` in pixels yourself (recommended) \n",
    "# diameter can be a list or a single number for all images\n",
    "# heart diameter = 80\n",
    "# U2OS diameter = 320\n",
    "\n",
    "masks, flows, styles, diams = model.eval(imgs, diameter=80, channels=channels, min_size=1000)\n",
    "\n",
    "#Filter tiny cells (artifacts) and expand by 5 pixels to smooth edges\n",
    "newmasks = []\n",
    "for mask in tqdm(masks):\n",
    "    newmask = mask.copy()\n",
    "    newmask = expand_labels(newmask, 3)\n",
    "    newmasks.append(newmask)\n",
    "\n",
    "savefiles = [os.path.join(save_dir, os.path.basename(file)) for file in files]\n",
    "#os.makedirs(save_dir)\n",
    "# save results so you can load in gui\n",
    "io.masks_flows_to_seg(imgs, newmasks, flows, diams, savefiles, channels)\n",
    "# save results as png\n",
    "io.save_to_png(imgs, newmasks, flows, savefiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the flat field correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fast, 1-2 seconds per FOV\n",
    "im_meds = pipeline.save_median_image_across_fovs(folders, analysis_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualize median images\n",
    "im = im_meds[3] # 0-3 is [750, 647, 561, 488] nm (laser wavelength)\n",
    "plt.figure()\n",
    "plt.imshow(im,vmax=8000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This step takes a long time (~30 minutes per FOV for an experiment with 45 probes)\n",
    "pipeline.flat_field_correction(folders, analysis_folder, fovs, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Select candidate spots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select two best colors (0 is first color in imaging round, 1 is second, etc.)\n",
    "colors_to_use = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "# load the masks if they are not already in the notebook\n",
    "segmentation_folder = analysis_folder+os.sep+r'segmentation'\n",
    "imgs = glob.glob(segmentation_folder+os.sep+r'Conv_zscan_*_seg.npy')\n",
    "masks = np.array([ np.load(img, allow_pickle=True).item()['masks'].T for img in imgs ])\n",
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the segmentation of one fov\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "fov_num = 7\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.imshow(masks[fov_num], cmap='seismic')\n",
    "plt.contour(masks[fov_num], [0.5+x for x in range(np.max(masks[fov_num]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#~70 seconds per FOV\n",
    "pipeline.get_candidate_spots(analysis_folder, masks, colors=colors_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Check PNG files with names ending in \"spots_selected_final\" in the analysis folder to view candidate spots selected</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Drift correction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import importlib\n",
    "importlib.reload(pipeline)\n",
    "dic = pickle.load(open(analysis_folder+os.sep+'Selected_Spot.pkl','rb'))\n",
    "fovs = np.unique(dic['class_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The 'jobs' parameter is how many FOVs to run simultaneously. \n",
    "#Each batch of jobs takes a few hours. No progress bar or any output is shown while running.\n",
    "pipeline.drift_correction_batch(folders, fovs, analysis_folder, colors, jobs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_fls = glob.glob(analysis_folder+os.sep+r'*_drift.npy')\n",
    "drifts = []\n",
    "for fl in drift_fls:\n",
    "    drifts.append(np.load(fl))\n",
    "drift = np.array(drifts)\n",
    "drift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Pretty fast, ~10 minutes\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "rounds = 42\n",
    "zxys_f, hs_f, cols_f, snrs_f, scores_f, all_scores_f, dic_spots, dic_drifts, dic_cell_ids, fovs_spots = pipeline.em_algorithm(analysis_folder, colors, rounds, blank_rounds=[25],\n",
    "                                                                                                                    chromatic_correction=r'D:\\ChromaticCorrection\\chromatic_corr_BB_5_28_2020.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data out so we can skip running EM in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(analysis_folder+os.sep+r'em_alg_zxys_f.npy', zxys_f)\n",
    "np.save(analysis_folder+os.sep+r'em_alg_hs_f.npy', hs_f)\n",
    "np.save(analysis_folder+os.sep+r'em_alg_cols_f.npy', cols_f)\n",
    "np.save(analysis_folder+os.sep+r'em_alg_snrs_f.npy', snrs_f)\n",
    "np.save(analysis_folder+os.sep+r'em_alg_scores_f.npy', scores_f)\n",
    "np.save(analysis_folder+os.sep+r'em_alg_all_scores_f.npy', all_scores_f)\n",
    "np.save(analysis_folder+os.sep+r'em_alg_dic_spots.npy', dic_spots)\n",
    "np.save(analysis_folder+os.sep+r'em_alg_dic_drifts.npy', dic_drifts)\n",
    "np.save(analysis_folder+os.sep+r'em_alg_dic_cell_ids.npy', dic_cell_ids)\n",
    "np.save(analysis_folder+os.sep+r'em_alg_fovs_spots.npy', fovs_spots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in the EM data if we have previously saved it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "zxys_f = np.load(analysis_folder+os.sep+r'em_alg_zxys_f.npy', allow_pickle=True)\n",
    "hs_f = np.load(analysis_folder+os.sep+r'em_alg_hs_f.npy', allow_pickle=True)\n",
    "cols_f = np.load(analysis_folder+os.sep+r'em_alg_cols_f.npy', allow_pickle=True)\n",
    "snrs_f = np.load(analysis_folder+os.sep+r'em_alg_snrs_f.npy', allow_pickle=True)\n",
    "scores_f = np.load(analysis_folder+os.sep+r'em_alg_scores_f.npy', allow_pickle=True)\n",
    "all_scores_f = np.load(analysis_folder+os.sep+r'em_alg_all_scores_f.npy', allow_pickle=True)\n",
    "dic_spots = np.load(analysis_folder+os.sep+r'em_alg_dic_spots.npy', allow_pickle=True)\n",
    "dic_drifts = np.load(analysis_folder+os.sep+r'em_alg_dic_drifts.npy', allow_pickle=True)\n",
    "dic_cell_ids = np.load(analysis_folder+os.sep+r'em_alg_dic_cell_ids.npy', allow_pickle=True)\n",
    "fovs_spots = np.load(analysis_folder+os.sep+r'em_alg_fovs_spots.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import FittingTools as ft\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['font.size'] = 15\n",
    "matplotlib.rcParams['font.family']='Arial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a histogram of scores for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "analysis_name = 'scratch'\n",
    "post_analysis_folder = pipeline.make_post_analysis_folder(analysis_folder, analysis_name)\n",
    "\n",
    "#########\n",
    "# a plot showing the overlap of the rejected spots (orange) versus the accepted ones (blue).\n",
    "# the blue and orange should be separated susbstiantially, and we choose our threshold below based on this. (log scale) \n",
    "\n",
    "# Adjusting this cutoff \n",
    "cutoff_exp = -em_threshold\n",
    "\n",
    "#########\n",
    "\n",
    "scores_all_rav = []\n",
    "nlen = np.max(list(map(len,all_scores_f)))\n",
    "scores_all_reg = [[] for i in range(nlen)]\n",
    "scores_all_bad = [[] for i in range(nlen)]\n",
    "for scores_cell in all_scores_f:\n",
    "    for ireg,scores_reg in enumerate(scores_cell):\n",
    "        scores_all_reg[ireg].extend(scores_reg)\n",
    "        scores_all_rav.extend(np.sort(scores_reg)[-4:-1]) # the 3 remaining spots after selecting the best\n",
    "        scores_all_bad[ireg].extend(np.sort(scores_reg)[:-1])\n",
    "vec = np.ravel(np.array(scores_f))\n",
    "vec = vec[np.isnan(vec)==False]\n",
    "\n",
    "fr = 1.*np.sum(scores_all_rav>np.exp(cutoff_exp))/len(scores_all_rav)\n",
    "txt_ = \"Est. FP: \"+str(np.round(fr*100,2))+'%'\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(np.log(vec),bins=1000,density=True,label='Accepted')\n",
    "plt.hist(np.log(scores_all_rav),bins=1000,alpha=0.5,density=True,label='Rejected')\n",
    "plt.vlines(cutoff_exp, 0, 0.5, 'r', linestyles='dashed')\n",
    "\n",
    "plt.xlabel(\"ln P-value\")\n",
    "plt.ylabel(\"Probability density\")\n",
    "plt.legend()\n",
    "plt.xlim((-19, 0))\n",
    "\n",
    "plt.title(\"Normalized Histogram of P-Values \\n for \"+experiment_name+'\\n Threshold:'+str(cutoff_exp)+\", \"+txt_);\n",
    "fig.savefig(post_analysis_folder+'histogram_p-values.pdf',bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'histogram_p-values.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Filter candidate chromosomes</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_fp_fn(coords, cell_ids, rnd=25):\n",
    "    # estimate the number of cells with 1 detection, 0 detections, and 2 detections at this stage.\n",
    "    cell_allele_state = []\n",
    "    for cid in np.unique(cell_ids):\n",
    "        locs = np.where(cell_ids == cid)\n",
    "        allele_presence = 1*[ (~np.isnan(coords[loc,rnd,0])) for loc in locs ][0]\n",
    "        cell_allele_state.append(allele_presence)\n",
    "    counts = [0,0,0]\n",
    "    for cell in cell_allele_state:\n",
    "        counts[sum(cell)] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "number_of_segments = 42\n",
    "max_segments_missing = 20\n",
    "############\n",
    "\n",
    "keep, zxys_clean_filtered, cell_ids_clean, hs_clean, scores_clean, fovs_spots_keep = pipeline.filter_chromosomes(42, max_segments_missing, zxys_f, hs_f, cols_f, scores_f, all_scores_f, dic_cell_ids, fovs_spots, cutoff_exp)\n",
    "print(\"Chromosomes after filtering: \"+str(len(zxys_clean_filtered)))\n",
    "zxys_clean_filtered, cell_ids_clean, chrs_keep = pipeline.top_two_chrs(zxys_clean_filtered, cell_ids_clean)\n",
    "hs_clean = hs_clean[chrs_keep]\n",
    "scores_clean = scores_clean[chrs_keep]\n",
    "fovs_spots_keep = fovs_spots_keep[chrs_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the number of cells with 1 detection, 0 detections, and 2 detections at this stage.\n",
    "counts = estimate_fp_fn(zxys_clean_filtered, cell_ids_clean)\n",
    "print(\"There are %d cells with a false negative, %d cells with one of each allele, and %d cells with a false positive.\" %(counts[0], counts[1], counts[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plot detection efficiency</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "total_len = float(len(zxys_clean_filtered))\n",
    "eff = [ 1-np.divide(float(np.sum(np.isnan(np.array(zxys_clean_filtered)[:,i,0]),axis=0)),total_len) \n",
    "       for i in range(zxys_clean_filtered.shape[1]) ]\n",
    "plt.bar(range(0,42),eff)\n",
    "plt.ylim((0.0,1.0))\n",
    "plt.hlines(np.mean(eff), -1, 42, colors='r', linestyle='dashed')\n",
    "plt.ylabel('Detection Efficiency (Fraction)', size=14)\n",
    "plt.xlabel('Imaging Round', size=14)\n",
    "plt.title(\"Detection efficiency by imaging round\\n for \"+experiment_name, size=24)\n",
    "plt.text(18,0.9,\"Average Efficiency: \"+str(100*np.round(np.mean(eff),2))+\"%\", size=14)\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(post_analysis_folder+'detection_efficiency.pdf',bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'detection_efficiency.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "vmin = 0  #Bottom of color scale (in nm)\n",
    "vmax = 700  #Top of color scale (in nm)\n",
    "#########\n",
    "\n",
    "import os\n",
    "\n",
    "zxys_clean_ = (zxys_clean_filtered)\n",
    "mats_clean = np.array(list(map(squareform,list(map(pdist,zxys_clean_)))))\n",
    "\n",
    "im = np.nanmedian(mats_clean[:,:42,:42],axis=0)# take the median image for the representative heatmap\n",
    "\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "plt.title('Median distance for\\n'+experiment_name+',\\n'+str(len(zxys_clean_))+' chromosomes', size=24)\n",
    "plt.ylabel('Genomic Region Number', size=14)\n",
    "plt.xlabel('Genomic Region Number', size=14)\n",
    "plt.imshow(im,vmin=vmin,vmax=vmax,cmap='seismic_r')\n",
    "plt.colorbar()\n",
    "fig.savefig(post_analysis_folder+'median_distance.pdf',bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'median_distance.png',bbox_inches='tight')\n",
    "np.save(analysis_folder+os.sep+r'median_distance_matrix.npy', im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contact map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "cutoff = 250  #Distance (nm) threshold for a contact\n",
    "########\n",
    "\n",
    "%matplotlib inline\n",
    "mat_ = 1.*np.sum(mats_clean<cutoff,axis=0)/np.sum(np.isnan(mats_clean),axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "plt.title('Contact map - cutoff:'+str(cutoff)+'nm\\n for '+experiment_name+'\\n'+str(len(mats_clean))+' chromosomes', size=24)\n",
    "plt.ylabel('Genomic Region Number', size=14)\n",
    "plt.xlabel('Genomic Region Number', size=14)\n",
    "plt.imshow(np.log(mat_),cmap='seismic')\n",
    "plt.colorbar()\n",
    "fig.savefig(post_analysis_folder+'contact_map.pdf',bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'contact_map.png',bbox_inches='tight')\n",
    "np.save(analysis_folder+os.sep+r'AJ_combine_matrix_contact.npy', mats_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Store some results in case they're needed later</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = post_analysis_folder+'saved_info.pkl'\n",
    "dic_save = {'master_folders':master_folders,'analysis_folder':analysis_folder,\n",
    "            'hs_f':np.array(hs_f),'zxys_f':np.array(zxys_f),\n",
    "            'scores_f':np.array(scores_f),\n",
    "            'fov_ids':np.array(fovs),\n",
    "            'hs_clean':hs_clean,\n",
    "            'keep_chromosomes':keep,\n",
    "            'log_score_cutoff':cutoff_exp,\n",
    "           'fovs_spots_keep':fovs_spots_keep,'zxys_clean_filtered':zxys_clean_filtered,\n",
    "           'scores_clean':scores_clean,\n",
    "           'scores_all_rav':scores_all_rav}\n",
    "pickle.dump(dic_save,open(save_file,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "ichr = 1245  #Chromosome ID to check (Between 0 and number stated in graphs above)\n",
    "##########\n",
    "zxys_clean_ = zxys_clean_filtered\n",
    "zxy = zxys_clean_[ichr]\n",
    "fov = fovs_spots_keep[ichr]\n",
    "\n",
    "ims_3d,zxys_im = pipeline.return_ims_pts(zxy, fov, readouts=None, master_folder=master_folders[0],\n",
    "                  analysis_folder=analysis_folder, cols=['750','647','561'], pix_size=[200,109,109],window=20)\n",
    "\n",
    "score_ = np.round(np.log(scores_clean[ichr]),2)\n",
    "titles = [str(iR+1)+': '+str(score_[iR]) for iR in np.arange(len(ims_3d))]\n",
    "%matplotlib inline\n",
    "fig = pipeline.plot_grid_ims(ims_3d,zxys_im,titles=titles,aratio=2.5,pos_txt=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Separate CAST and 129 alleles</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "cell_names = []\n",
    "cast_129_diff = 0.5\n",
    "\n",
    "cell_ids = np.array(np.arange(len(zxys_clean_filtered))/2,dtype=int) # create a list of length zxys, integer divide by 2 to make doubles\n",
    "cell_ids_keep = cell_ids_clean # remove all bad ones identified above (post EM step)\n",
    "zyxs = zxys_clean_filtered.copy()\n",
    "hs = hs_clean.copy()\n",
    "hs[np.isnan(zyxs[:,:,0])]=np.nan\n",
    "cids = cell_ids_keep.copy()\n",
    "round_to_sort = 25\n",
    "\n",
    "cids_,cts_= np.unique(cids,return_counts=True)\n",
    "cids_kp = cids_[cts_==2] #indices of cells that have two remaining homologs\n",
    "cell_ids_clean_, cids_clean_cts_ = np.unique(cell_ids_clean,return_counts=True)\n",
    "cids_clean_kp = cell_ids_clean_[cids_clean_cts_==2]\n",
    "hmin=np.nanmedian(hs)/2\n",
    "zxys_cast = []\n",
    "hs_cast = []\n",
    "zxys_noncast = []\n",
    "hs_noncast = []\n",
    "cids_final = []\n",
    "ignore = []\n",
    "print(\"Ignoring \" +str(len(ignore))+ \" manually selected cells.\")\n",
    "\n",
    "for cid,cname in zip(cids_kp, cids_clean_kp):\n",
    "    if cid in ignore:\n",
    "        continue\n",
    "    keep_homs = cids==cid\n",
    "    zxy1,zxy2 = zyxs[keep_homs]\n",
    "    h1s,h2s = hs[keep_homs,:]\n",
    "    h1,h2 = h1s[round_to_sort],h2s[round_to_sort]\n",
    "    if h1>hmin and not(h2>cast_129_diff*h1):\n",
    "        zxys_cast.append(zxy1)\n",
    "        hs_cast.append(h1s)\n",
    "        zxys_noncast.append(zxy2)\n",
    "        hs_noncast.append(h2s)\n",
    "        cids_final.append(cid)\n",
    "        cell_names.append(cname)\n",
    "    if h2>hmin and not(h1>cast_129_diff*h2):\n",
    "        cids_final.append(cid)\n",
    "        zxys_cast.append(zxy2)\n",
    "        hs_cast.append(h2s)\n",
    "        zxys_noncast.append(zxy1)\n",
    "        hs_noncast.append(h1s)\n",
    "        cell_names.append(cname)\n",
    "        \n",
    "filename = post_analysis_folder+os.sep+\"cast_allele_coords.npy\"\n",
    "zxys_cast_corr = np.array(zxys_cast)\n",
    "np.save(filename, zxys_cast_corr)\n",
    "filename = post_analysis_folder+os.sep+\"129_allele_coords.npy\"\n",
    "np.save(filename, (np.array(zxys_noncast)))\n",
    "zxys_noncast_corr = np.array(zxys_noncast)\n",
    "filename = post_analysis_folder+os.sep+\"cids_final.npy\"\n",
    "cids_final = np.save(filename,np.array(cids_final))\n",
    "\n",
    "print(\"Number of cells:\",len(zxys_noncast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save coordinates to file\n",
    "p = [8,9,10]     #Segments that include the promoter (counting from 0)\n",
    "e = [30,31,32]   #Segments that include the super-enhancer (counting from 0)\n",
    "\n",
    "def get_dists(zxys):\n",
    "    dists_ep = []\n",
    "    for p_i in p:\n",
    "        for e_i in e:\n",
    "            p_ = np.nanmedian(np.array(zxys)[:,[p_i]],axis=1)#if feature spans multiple regions get the mean position\n",
    "            e_ = np.nanmedian(np.array(zxys)[:,[e_i]],axis=1)\n",
    "            dists_ep.append(np.linalg.norm(p_-e_,axis=-1))\n",
    "\n",
    "    dists_ep = np.nanmedian(dists_ep,axis=0)\n",
    "    return dists_ep\n",
    "\n",
    "def get_insulation(zxys,a,b,c,func=np.nanmedian):\n",
    "    distances_in_domAB_and_domBC = np.array([list(pdist(zxy_[a:b]))+list(pdist(zxy_[b:c])) for zxy_ in zxys])\n",
    "    distances_between_domains = np.array([cdist(zxy_[a:b],zxy_[b:c]).ravel() for zxy_ in zxys])\n",
    "    insulation = func(distances_between_domains,axis=-1)/func(distances_in_domAB_and_domBC,axis=-1)\n",
    "    insulation = insulation[~np.isnan(insulation)]\n",
    "    return insulation\n",
    "\n",
    "def get_rgs(zxys,e1,e2,remove_nan=True):\n",
    "    zxys_ = np.array(zxys)[:,e1:e2].copy()\n",
    "    zxys_ -= np.nanmean(zxys_,axis=1)[:,np.newaxis]\n",
    "    zxys_ = np.linalg.norm(zxys_,axis=-1)\n",
    "    rg_cats = np.sqrt(np.nanmean(zxys_**2,axis=-1))\n",
    "    if remove_nan:\n",
    "        rg_cats = rg_cats[~np.isnan(rg_cats)]\n",
    "    return rg_cats\n",
    "\n",
    "ins_CAST = np.log(get_insulation(zxys_cast,9,25,33))\n",
    "ins_129 = np.log(get_insulation(zxys_noncast,9,25,33))\n",
    "\n",
    "dists_ep_cast = get_dists(zxys_cast)\n",
    "dists_ep_noncast = get_dists(zxys_noncast)\n",
    "\n",
    "rgs_cast = get_rgs(zxys_cast,10,25)\n",
    "rgs_noncast = get_rgs(zxys_noncast,10,25)\n",
    "\n",
    "cast_median = np.nanmedian(zxys_cast,axis=1)\n",
    "noncast_median = np.nanmedian(zxys_noncast,axis=1)\n",
    "\n",
    "headers = ['CAST_z', 'CAST_x', 'CAST_y', '129_z', '129_x', '129_y', 'cell_id', 'CAST_ep_dist',\n",
    "           '129_ep_dist', 'CAST_ins', '129_ins', 'CAST_rgs_10_25', '129_rgs_10_25',\n",
    "           'CAST_rgs_10_33', '129_rgs_10_33', 'CAST_rgs_1_42', '129_rgs_1_42', 'CAST_rgs_10_39', '129_rgs_10_39',\n",
    "           'CAST_rgs_25_33', '129_rgs_25_33']\n",
    "extra_data = zip(cell_names, dists_ep_cast, dists_ep_noncast, ins_CAST, ins_129,\n",
    "                 get_rgs(zxys_cast,10,25), get_rgs(zxys_noncast,10,25),\n",
    "                 get_rgs(zxys_cast,10,33), get_rgs(zxys_noncast,10,33),\n",
    "                 get_rgs(zxys_cast,1,42), get_rgs(zxys_noncast,1,42),\n",
    "                 get_rgs(zxys_cast,10,39), get_rgs(zxys_noncast,10,39),\n",
    "                 get_rgs(zxys_cast,25,33), get_rgs(zxys_noncast,25,33)\n",
    "                )\n",
    "\n",
    "with open(post_analysis_folder+os.sep+'single_cell_data.csv', 'w') as f:\n",
    "    print(','.join(headers), file=f)\n",
    "    for cast_coords, noncast_coords, extra in zip(cast_median, noncast_median, extra_data):\n",
    "        print(','.join([str(x) for x in cast_coords])+\",\"+','.join([str(x) for x in noncast_coords])+\",\"+','.join([str(x) for x in extra]), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Plot: Median distance heatmap for CAST alleles</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "vmin = 0  #Bottom of color scale (in nm)\n",
    "vmax = 700  #Top of color scale (in nm)\n",
    "#########\n",
    "\n",
    "zxys_clean_ = copy.deepcopy(zxys_cast_corr)\n",
    "mats_clean_cast = np.array(list(map(squareform,list(map(pdist,zxys_clean_)))))\n",
    "\n",
    "im_cast = np.nanmedian(mats_clean_cast[:,:42,:42],axis=0)# take the median image for the representative heatmap\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "plt.title('Median distance - CAST\\n for '+experiment_name+'\\n'+str(len(zxys_clean_))+' chromosomes', size=24)\n",
    "plt.ylabel('Genomic Region Number', size=14)\n",
    "plt.xlabel('Genomic Region Number', size=14)\n",
    "plt.imshow(im_cast,vmin=vmin,vmax=vmax,cmap='seismic_r')\n",
    "plt.colorbar()\n",
    "fig.savefig(post_analysis_folder+'median_distance-CAST.pdf',bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'median_distance-CAST.png',bbox_inches='tight')\n",
    "np.save(analysis_folder+os.sep+r'CAST_median_matrix.npy', im_cast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Plot: Median distance heatmap for 129 alleles</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "vmin = 0  #Bottom of color scale (in nm)\n",
    "vmax = 700  #Top of color scale (in nm)\n",
    "#########\n",
    "\n",
    "zxys_clean_ = copy.deepcopy(zxys_noncast_corr)\n",
    "#zxys_clean_[:,round_to_sort]=np.nan\n",
    "mats_clean_129 = np.array(list(map(squareform,list(map(pdist,zxys_clean_)))))\n",
    "\n",
    "im_129 = np.nanmedian(mats_clean_129[:,:42,:42],axis=0)# take the median image for the representative heatmap\n",
    "im_129[:,round_to_sort] = np.nan\n",
    "im_129[round_to_sort,:] = np.nan\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "plt.title('Median distance - 129\\n for '+experiment_name+'\\n'+str(len(zxys_clean_))+' chromosomes', size=24)\n",
    "plt.ylabel('Genomic Region Number', size=14)\n",
    "plt.xlabel('Genomic Region Number', size=14)\n",
    "plt.imshow(im_129,vmin=vmin,vmax=vmax,cmap='seismic_r')\n",
    "plt.colorbar()\n",
    "fig.savefig(post_analysis_folder+'median_distance-129.pdf', bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'median_distance-129.png', bbox_inches='tight')\n",
    "np.save(analysis_folder+os.sep+r'129_median_matrix.npy', im_129)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Plot: Contact frequency heatmap for CAST alleles</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "cutoff = 200  #Distance (nm) threshold for a contact\n",
    "########\n",
    "\n",
    "zxys_clean_ = copy.deepcopy(zxys_cast_corr)\n",
    "mats_clean = np.array(list(map(squareform,list(map(pdist,zxys_clean_)))))\n",
    "\n",
    "mat_cast = 1.*np.sum(mats_clean<cutoff,axis=0)/np.sum(mats_clean>=0,axis=0)\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "plt.ylabel('Genomic Region Number', size=14)\n",
    "plt.xlabel('Genomic Region Number', size=14)\n",
    "plt.title('Contact map - CAST - cutoff:'+str(cutoff)+'nm\\n for '+experiment_name+'\\n'+str(len(mats_clean))+' chromosomes', size=24)\n",
    "ax = plt.imshow(np.log(mat_cast),cmap='seismic')\n",
    "vmin,vmax = ax.get_clim()\n",
    "plt.colorbar()\n",
    "fig.savefig(post_analysis_folder+'contact_map-CAST.pdf', bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'contact_map-CAST.png', bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'contact_map-CAST.svg', bbox_inches='tight')\n",
    "np.save(analysis_folder+os.sep+r'CAST_log_contact.npy', np.log(mat_cast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Plot: Contact frequency heatmap for 129 alleles</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "cutoff = 200  #Distance (nm) threshold for a contact\n",
    "########\n",
    "\n",
    "zxys_clean_ = copy.deepcopy(zxys_noncast_corr)\n",
    "zxys_clean_[:,round_to_sort]=np.nan\n",
    "mats_clean = np.array(list(map(squareform,list(map(pdist,zxys_clean_)))))\n",
    "\n",
    "mat_129 = 1.*np.sum(mats_clean<cutoff,axis=0)/np.sum(mats_clean>=0,axis=0)\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "plt.ylabel('Genomic Region Number', size=14)\n",
    "plt.xlabel('Genomic Region Number', size=14)\n",
    "plt.title('Contact map - 129 - cutoff:'+str(cutoff)+'nm\\nfor '+experiment_name+'\\n'+str(len(mats_clean))+' chromosomes', size=24)\n",
    "plt.imshow(np.log(mat_129),cmap='seismic',vmin=vmin,vmax=vmax)\n",
    "plt.colorbar()\n",
    "fig.savefig(post_analysis_folder+'contact_map-129.pdf', bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'contact_map-129.png', bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'contact_map-129.svg', bbox_inches='tight')\n",
    "np.save(analysis_folder+os.sep+r'129_log_contact.npy', np.log(mat_129))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Plot: Difference of median distance (129-CAST)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "plt.ylabel('Genomic Region Number', size=14)\n",
    "plt.xlabel('Genomic Region Number', size=14)\n",
    "plt.title('Difference Matrix (129-CAST)\\nfor '+experiment_name+'\\n'+str(len(zxys_clean_))+' chromosomes',size=24)\n",
    "plt.imshow(im_129-im_cast,cmap='seismic_r',vmin=-75,vmax=75)\n",
    "plt.colorbar();\n",
    "fig.savefig(post_analysis_folder+'diff_of_medians.pdf', bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'diff_of_medians.png', bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'diff_of_medians.svg', bbox_inches='tight')\n",
    "np.save(analysis_folder+os.sep+r'diff_of_medians.npy', im_129-im_cast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Plot: Log-difference of contact frequency (CAST-129)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "plt.ylabel('Genomic Region Number', size=14)\n",
    "plt.xlabel('Genomic Region Number', size=14)\n",
    "plt.title('Log-difference of contact\\n (129-CAST) - '+'Cutoff:'+str(cutoff)+'nm\\nfor '+experiment_name+'\\n'+str(len(zxys_clean_))+' chromosomes',size=24)\n",
    "plt.imshow(np.log(mat_129)-np.log(mat_cast),cmap='seismic', vmax=1.0, vmin=-1.0)\n",
    "plt.colorbar()\n",
    "fig.savefig(post_analysis_folder+'log_diff_contact.pdf', bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'log_diff_contact.png', bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+'log_diff_contact.svg', bbox_inches='tight')\n",
    "np.save(analysis_folder+os.sep+r'log_diff_of_contact.npy', np.log(mat_129)-np.log(mat_cast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Single-cell analysis</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Enhancer-promoter distance comparison between alleles</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "p = [9,10,11]     #Segments that include the promoter (counting from 0)\n",
    "e = [30,31,32]   #Segments that include the super-enhancer (counting from 0)\n",
    "#########\n",
    "\n",
    "def get_dists(zxys):\n",
    "    dists_ep = []\n",
    "    for p_i in p:\n",
    "        for e_i in e:\n",
    "            p_ = np.nanmedian(np.array(zxys)[:,[p_i]],axis=1)#if feature spans multiple regions get the mean position\n",
    "            e_ = np.nanmedian(np.array(zxys)[:,[e_i]],axis=1)\n",
    "            dists_ep.append(np.linalg.norm(p_-e_,axis=-1))\n",
    "\n",
    "    dists_ep = np.nanmedian(dists_ep,axis=0)\n",
    "    dists_ep = dists_ep[~np.isnan(dists_ep)]#keep valid distances\n",
    "    return dists_ep\n",
    "\n",
    "dists_ep_cast = get_dists(zxys_cast)\n",
    "dists_ep_noncast = get_dists(zxys_noncast)\n",
    "savepath = post_analysis_folder+os.sep+r'cast_e_p_dists.npy'\n",
    "np.save(savepath, dists_ep_cast)\n",
    "savepath = post_analysis_folder+os.sep+r'noncast_e_p_dists.npy'\n",
    "np.save(savepath, dists_ep_noncast)\n",
    "\n",
    "res = ranksums(dists_ep_cast,dists_ep_noncast)\n",
    "pvalue = res[-1]\n",
    "pvalue\n",
    "\n",
    "bins=np.linspace(0,800,16)\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "plt.hist(dists_ep_cast,bins=bins,density=True,label='CAST (median = {:.0f}nm)'.format(np.nanmedian(dists_ep_cast)), edgecolor='white', linewidth=0.9);\n",
    "plt.hist(dists_ep_noncast,bins=bins,density=True,alpha=0.75,label='129 (median = {:.0f}nm)'.format(np.nanmedian(dists_ep_noncast)), edgecolor='white', linewidth=0.9);\n",
    "#plt.legend()\n",
    "plt.title(experiment_name+\" single cell \\n contact for \"+str(p)+' and '+str(e)+\"\\nWilcoxon p-value = {}\".format(str(pvalue)), size=24)\n",
    "plt.xlabel('Distance E-P',size=14)\n",
    "plt.ylabel('Probability density',size=14)\n",
    "plt.legend(['CAST = '+str(np.round(np.nanmedian(dists_ep_cast),1)), '129 = '+str(np.round(np.nanmedian(dists_ep_noncast),1)) ])\n",
    "plt.savefig(post_analysis_folder+'enh_prom_distance.pdf',dpi=300,bbox_inches=\"tight\")\n",
    "plt.savefig(post_analysis_folder+'enh_prom_distance.png',dpi=300,bbox_inches=\"tight\")\n",
    "plt.savefig(post_analysis_folder+'enh_prom_distance.svg',dpi=300,bbox_inches=\"tight\")\n",
    "print(np.nanmedian(dists_ep_cast))\n",
    "print(np.nanmedian(dists_ep_noncast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Correlations of E-P dists between alleles within each cell</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dists_nans(zxys):\n",
    "    dists_ep = []\n",
    "    for p_i in p:\n",
    "        for e_i in e:\n",
    "            p_ = np.nanmedian(np.array(zxys)[:,[p_i]],axis=1)#if feature spans multiple regions get the mean position\n",
    "            e_ = np.nanmedian(np.array(zxys)[:,[e_i]],axis=1)\n",
    "            dists_ep.append(np.linalg.norm(p_-e_,axis=-1))\n",
    "\n",
    "    dists_ep = np.nanmedian(dists_ep,axis=0)\n",
    "    return dists_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "dists_ep_cast_nans = get_dists_nans(zxys_cast)\n",
    "dists_ep_noncast_nans = get_dists_nans(zxys_noncast)\n",
    "\n",
    "#find valid pairs\n",
    "valid_pairs = np.where(np.array(~np.isnan(dists_ep_cast_nans)*~np.isnan(dists_ep_noncast_nans)))\n",
    "dists_ep_cast_nans = dists_ep_cast_nans[valid_pairs]\n",
    "dists_ep_noncast_nans = dists_ep_noncast_nans[valid_pairs]\n",
    "\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "plt.scatter(dists_ep_noncast_nans, dists_ep_cast_nans, alpha=0.5)\n",
    "plt.title(experiment_name+\"\\nCorrelation of CAST vs 129 E-P distance\\n\"+str(len(mats_clean))+' cells', size=24)\n",
    "plt.ylabel(\"E-P Distance CAST (nm)\", size=20)\n",
    "plt.xlabel(\"E-P Distance 129 (nm)\", size=20)\n",
    "plt.text(2500,3000, pearsonr(dists_ep_noncast_nans, dists_ep_cast_nans)[0],size=14)\n",
    "fig.savefig(post_analysis_folder+os.sep+'E-P_cast_129_corr.pdf',bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+os.sep+'E-P_cast_129_corr.png',bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+os.sep+'E-P_cast_129_corr.svg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Enhancer-promoter contact comparison</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "contact_distance = 200   #Distance (nm) threshold for contact\n",
    "#########\n",
    "\n",
    "cast_fraction = 1.*np.sum(dists_ep_cast<contact_distance)/np.sum(dists_ep_cast>=0)\n",
    "noncast_fraction = 1.*np.sum(dists_ep_noncast<contact_distance)/np.sum(dists_ep_noncast>=0)\n",
    "#Fisher's exact test for contact < contact_distance (nm)\n",
    "from scipy.stats import fisher_exact\n",
    "cast_contact = np.sum(dists_ep_cast<=contact_distance)\n",
    "cast_none = np.sum(dists_ep_cast>contact_distance)\n",
    "wt_contact = np.sum(dists_ep_noncast<=contact_distance)\n",
    "wt_none = np.sum(dists_ep_noncast>contact_distance)\n",
    "print(f\"\\t<={contact_distance}\\t>{contact_distance}\")\n",
    "print(f\"CAST\\t{cast_contact}\\t{cast_none}\")\n",
    "print(f\"129\\t{wt_contact}\\t{wt_none}\")\n",
    "table = [[cast_contact,cast_none],[wt_contact,wt_none]]\n",
    "oddsratio, pvalue = fisher_exact(table)\n",
    "print(\"\\nFisher exact test\")\n",
    "print(f\"Odds ratio: {oddsratio}\")\n",
    "print(f\"P-value: {pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "minimum = 200\n",
    "maximum = 750\n",
    "step = 25\n",
    "#########\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "def enh_prom_distance_ratio(threshold):\n",
    "    cast_contact = np.sum(dists_ep_cast<=threshold)\n",
    "    cast_none = np.sum(dists_ep_cast>threshold)\n",
    "    wt_contact = np.sum(dists_ep_noncast<=threshold)\n",
    "    wt_none = np.sum(dists_ep_noncast>threshold)\n",
    "    return (float(cast_contact) / (cast_contact+cast_none)) / (float(wt_contact) / (wt_contact+wt_none))\n",
    "\n",
    "dists = list(range(minimum,maximum,step))\n",
    "ratio_nums = [enh_prom_distance_ratio(thresh) for thresh in dists]\n",
    "#smoothing\n",
    "#smooth = [sum(ratio_nums[i-25:i+26]) / 51.0 for i in range(105,650)]\n",
    "fig,ax = plt.subplots(figsize=(6,5))\n",
    "plt.xlabel(\"E-P contact threshold (nm)\",size=14)\n",
    "plt.ylabel(\"CAST/129 contact frequency ratio\",size=14)\n",
    "plt.title(experiment_name+\"\\nE-P constact ratio (CAST/129)\", size=24)\n",
    "plot = sns.lineplot(dists, ratio_nums)\n",
    "plt.show(plot)\n",
    "ax = fig.add_subplot(111)\n",
    "plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "ax.tick_params(width=1.5, length=4, labelsize=8)\n",
    "\n",
    "savefile = post_analysis_folder+os.sep+\"E-P_ratio_line.npy\"\n",
    "np.save(savefile, np.array(list(zip(ratio_nums, dists))))\n",
    "\n",
    "plt.savefig(post_analysis_folder+'ep_threshold.pdf',dpi=300,bbox_inches=\"tight\")\n",
    "plt.savefig(post_analysis_folder+'ep_threshold.png',dpi=300,bbox_inches=\"tight\")\n",
    "plt.savefig(post_analysis_folder+'ep_threshold.svg',dpi=300,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Radius of gyration</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "regions_to_plot = [(9,33), (9,25), (26,33), (26,42), (0,25), (0,42)]\n",
    "########\n",
    "\n",
    "def get_rgs(zxys_cast_,remove_nan=True):\n",
    "    zxys_cast_ -= np.nanmean(zxys_cast_,axis=1)[:,np.newaxis]\n",
    "    zxys_cast_ = np.linalg.norm(zxys_cast_,axis=-1)\n",
    "    rg_cats = np.sqrt(np.nanmean(zxys_cast_**2,axis=-1))\n",
    "    if remove_nan:\n",
    "        rg_cats = rg_cats[~np.isnan(rg_cats)]\n",
    "    return rg_cats\n",
    "\n",
    "\n",
    "def histogram_rgs(zxys_cast,zxys_noncast,edges=[9,33],bins=np.linspace(50,500,16)):\n",
    "    e1,e2 = edges\n",
    "    zxys_cast_ = np.array(zxys_cast)[:,e1:e2].copy()\n",
    "    rgs_cast = get_rgs(zxys_cast_)\n",
    "    zxys_noncast_ = np.array(zxys_noncast)[:,e1:e2].copy()\n",
    "    rgs_noncast = get_rgs(zxys_noncast_)\n",
    "    fig = plt.figure(figsize=(5.5,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "    ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "    \n",
    "    plt.hist(rgs_cast,bins=bins,density=True,alpha=0.75,label='CAST - median(nm):'+str(int(np.median(rgs_cast))), edgecolor='white', linewidth=0.9)\n",
    "    plt.hist(rgs_noncast,bins=bins,density=True,alpha=0.75,label='129 - median(nm):'+str(int(np.median(rgs_noncast))), edgecolor='white', linewidth=0.9)\n",
    "    #plt.legend()\n",
    "    plt.ylabel(\"Probability density\",size=14)\n",
    "    plt.xlabel(\"Radius of gyration(nm)\",size=14)\n",
    "    res = ranksums(rgs_cast,rgs_noncast)\n",
    "    pvalue = res[-1]\n",
    "    plt.title('Radius of gyration of regions '+str(e1+1)+'-'+str(e2)+'\\n'+experiment_name+'\\np-value Wilcoxon: '+str(pvalue), size=24)\n",
    "    fig.savefig(post_analysis_folder+'radiusgyration_'+str(e1+1)+'-'+str(e2)+'.pdf',dpi=300,bbox_inches=\"tight\")\n",
    "    fig.savefig(post_analysis_folder+'radiusgyration_'+str(e1+1)+'-'+str(e2)+'.png',dpi=300,bbox_inches=\"tight\")\n",
    "    fig.savefig(post_analysis_folder+'radiusgyration_'+str(e1+1)+'-'+str(e2)+'.svg',dpi=300,bbox_inches=\"tight\")\n",
    "    return fig,rgs_cast,rgs_noncast\n",
    "\n",
    "for region in regions_to_plot:\n",
    "    histogram_rgs(zxys_cast,zxys_noncast,edges=region,bins=np.linspace(50,500,16));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Insulation of domains</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#########\n",
    "#Insulation of regions start-middle and middle-end\n",
    "start = 9\n",
    "middle = 25\n",
    "end = 33\n",
    "#########\n",
    "\n",
    "def get_insulation(zxys,a,b,c,func=np.nanmedian):\n",
    "    distances_in_domAB_and_domBC = np.array([list(pdist(zxy_[a:b]))+list(pdist(zxy_[b:c])) for zxy_ in zxys])\n",
    "    distances_between_domains = np.array([cdist(zxy_[a:b],zxy_[b:c]).ravel() for zxy_ in zxys])\n",
    "    insulation = func(distances_between_domains,axis=-1)/func(distances_in_domAB_and_domBC,axis=-1)\n",
    "    insulation = insulation[~np.isnan(insulation)]\n",
    "    return insulation\n",
    "\n",
    "def insulation_figure(zxys_cast,zxys_noncast,a,b,c,bins = np.linspace(-1,1,30)):\n",
    "    ins_CAST = np.log(get_insulation(zxys_cast,a,b,c))\n",
    "    ins_129 = np.log(get_insulation(zxys_noncast,a,b,c))\n",
    "    fig =  plt.figure(figsize=(8,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "    ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "    plt.hist(ins_CAST,density=True,bins=bins,alpha=0.75,label='CAST - median:'+str(np.round(np.median(ins_CAST),2)), edgecolor='white', linewidth=0.9)\n",
    "    plt.hist(ins_129,density=True,bins=bins,alpha=0.75,label='129 - median:'+str(np.round(np.median(ins_129),2)), edgecolor='white', linewidth=0.9)\n",
    "    plt.xlabel('Log-insulation score\\n (median distances between/median distance within domains)',size=14)\n",
    "    plt.ylabel('Prbability density\\nacross cells',size=14)\n",
    "    #plt.legend()\n",
    "    res = ranksums(ins_CAST,ins_129)\n",
    "    pvalue = res[-1]\n",
    "    \n",
    "    plt.title('Single cell insulation of domains '+str((a+1,b))+'- '+str((b+1,c))+'\\np-value -wilcoxon:'+str(pvalue),size=24)\n",
    "    fig.savefig(post_analysis_folder+'insulation.pdf',dpi=300,bbox_inches=\"tight\")\n",
    "    fig.savefig(post_analysis_folder+'insulation.png',dpi=300,bbox_inches=\"tight\")\n",
    "    fig.savefig(post_analysis_folder+'insulation.svg',dpi=300,bbox_inches=\"tight\")\n",
    "    return fig,ins_CAST,ins_129\n",
    "\n",
    "zxys_cast = np.array(zxys_cast)\n",
    "zxys_noncast = np.array(zxys_noncast)\n",
    "\n",
    "fig,ins_CAST,ins_129 = insulation_figure(zxys_cast,zxys_noncast,start,middle,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import DomainTools as dt\n",
    "dom_sz = 6\n",
    "cutoff = 0.33\n",
    "dom_starts_all_cast = []\n",
    "for zxy_ in (zxys_cast):\n",
    "\n",
    "    bad = np.where(np.isnan(zxy_[:,0]))[0]\n",
    "    zxy__ = np.array([dt.interp1dnan(x_) for x_ in zxy_.T]).T\n",
    "\n",
    "    zxy___ = zxy__\n",
    "    \n",
    "    #get initial guess of where a domains boundary is\n",
    "    dists = np.array([np.linalg.norm(np.nanmean(zxy___[max(i-dom_sz,0):i],axis=0)-\\\n",
    "                            np.nanmean(zxy___[i:i+dom_sz],axis=0)) \n",
    "                              for i in range(len(zxy___))])\n",
    "    bds = dt.get_ind_loc_max(dists,cutoff_max=0,valley=dom_sz)\n",
    "    dom_starts= [0]+[dm for dm in bds if dm>1 and dm<len(zxy___)-2]\n",
    "    mat = squareform(pdist(zxy___))\n",
    "    dom_starts_ = dom_starts\n",
    "    # fuse domains untill cannot fuse anymore based on cutoff.\n",
    "    if len(dom_starts)>1:\n",
    "        dom_starts_,seps = dt.fuse_doms(mat,dom_starts,tag='median',cut_off=cutoff)\n",
    "    dom_starts_all_cast+=[dom_starts_[1:]]\n",
    "    if False:\n",
    "        plt.figure()\n",
    "        plt.imshow(mat,vmax=800,cmap='seismic_r')\n",
    "        plt.plot(dom_starts_,dom_starts_,'go')\n",
    "        \n",
    "dom_starts_all_noncast = []\n",
    "for zxy_ in (zxys_noncast):\n",
    "\n",
    "    bad = np.where(np.isnan(zxy_[:,0]))[0]\n",
    "    zxy__ = np.array([dt.interp1dnan(x_) for x_ in zxy_.T]).T\n",
    "\n",
    "    zxy___ = zxy__\n",
    "    dists = np.array([np.linalg.norm(np.nanmean(zxy___[max(i-dom_sz,0):i],axis=0)-\\\n",
    "                            np.nanmean(zxy___[i:i+dom_sz],axis=0)) \n",
    "                              for i in range(len(zxy___))])\n",
    "    bds = dt.get_ind_loc_max(dists,cutoff_max=0,valley=dom_sz)\n",
    "    dom_starts= [0]+[dm for dm in bds if dm>1 and dm<len(zxy___)-2]\n",
    "    mat = squareform(pdist(zxy___))\n",
    "    dom_starts_ = dom_starts\n",
    "    if len(dom_starts)>1:\n",
    "        dom_starts_,seps = dt.fuse_doms(mat,dom_starts,tag='median',cut_off=cutoff)\n",
    "    dom_starts_all_noncast+=[dom_starts_[1:]]\n",
    "    if False:\n",
    "        plt.figure()\n",
    "        plt.imshow(mat,vmax=800,cmap='seismic_r')\n",
    "        plt.plot(dom_starts_,dom_starts_,'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bds_all = [e for dm in dom_starts_all_cast for e in dm]\n",
    "fig = dt.fig_no_axis(figsize=(10,6))\n",
    "fracs = np.bincount(bds_all)/float(len(dom_starts_all_cast))\n",
    "fracs[:dom_sz-1]=np.nan\n",
    "fracs[-dom_sz+1:]=np.nan\n",
    "#fracs = np.insert(np.delete(fracs, 25), 38, np.nan)\n",
    "np.save(post_analysis_folder+ os.sep+r\"boundary_prob_cast.npy\", fracs)\n",
    "plt.plot(fracs,'.-',label='CAST', linewidth=8)\n",
    "\n",
    "bds_all = [e for dm in dom_starts_all_noncast for e in dm]\n",
    "fracs = np.bincount(bds_all)/float(len(dom_starts_all_noncast))\n",
    "fracs[:dom_sz-1]=np.nan\n",
    "fracs[-dom_sz+1:]=np.nan\n",
    "#fracs = np.insert(np.delete(fracs, 25), 38, np.nan)\n",
    "np.save(post_analysis_folder+ os.sep+r\"boundary_prob_129.npy\", fracs)\n",
    "plt.plot(fracs,'.-',label='129', linewidth=8)\n",
    "\n",
    "plt.xticks(np.arange(fracs.shape[0],step=5), np.arange(1,fracs.shape[0]+1,step=5))\n",
    "plt.ylabel('Boundary probability',size=14)\n",
    "plt.xlabel('Genomic coordinate',size=14)\n",
    "#plt.axvline(25,linestyle='--', color='black',linewidth=2)\n",
    "plt.ylim(0,0.20)\n",
    "plt.title(\"Boundary Probability for\\n\"+experiment_name)\n",
    "plt.legend()\n",
    "filename = post_analysis_folder+os.sep+r'\\Bondary_prob_'+experiment_name[:5]+'.pdf'\n",
    "plt.savefig(filename, format='pdf', dpi=400, bbox_inches='tight')\n",
    "filename = post_analysis_folder+os.sep+r'\\Bondary_prob_'+experiment_name[:5]+'.png'\n",
    "plt.savefig(filename, format='png', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "        \n",
    "def centeroidnp(trace):\n",
    "    length = trace.shape[0]\n",
    "    sum_x = np.nansum(trace[:, 1])\n",
    "    sum_y = np.nansum(trace[:, 2])\n",
    "    sum_z = np.nansum(trace[:, 0])\n",
    "    return sum_z/(length-sum(np.isnan(trace[:, 0]))), sum_x/(length-sum(np.isnan(trace[:, 1]))), sum_y/(length-sum(np.isnan(trace[:, 2])))\n",
    "\n",
    "def get_dists_from_ctr(array):\n",
    "\n",
    "    geometric_distances = np.zeros((array.shape[0], array.shape[1]))\n",
    "\n",
    "    # go through each trace\n",
    "    for idx, trace in enumerate(array):\n",
    "\n",
    "            #get trace centeroid\n",
    "        trace_center = np.array(centeroidnp(trace))\n",
    "\n",
    "            # compute distance between centeroid and each point (returns a 42 element array for each trace)\n",
    "        centeroid_distances = np.array([ np.linalg.norm(x) for x in (trace-trace_center) ])\n",
    "\n",
    "        geometric_distances[idx] = centeroid_distances\n",
    "\n",
    "    return geometric_distances\n",
    "    \n",
    "cast = get_dists_from_ctr(zxys_cast_corr)\n",
    "noncast = get_dists_from_ctr(zxys_noncast_corr)\n",
    "noncast[:,25] = np.nan\n",
    "\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.setp(ax.spines.values(), linewidth=1.5)\n",
    "ax.tick_params(width=1.5, length=4, labelsize=14)\n",
    "plt.title('Median distance from geometric center for\\n'+experiment_name+\", \"+str(len(cast))+' chromosomes', size=24)\n",
    "plt.ylabel('Median Distance from geometric center', size=14)\n",
    "plt.xlabel('Genomic Region Number', size=14)\n",
    "plt.ylim((100,max(np.nanmedian(noncast, axis=0))+50))\n",
    "plt.plot(range(42), np.nanmedian(cast, axis=0), marker='o', color='#1f77b4')\n",
    "plt.errorbar(range(42), np.nanmedian(cast, axis=0), yerr=1.96*np.nanstd(cast)/np.sqrt(sum(np.isnan(cast))), color='#1f77b4')\n",
    "plt.plot(range(42), np.nanmedian(noncast, axis=0), marker='o', color='#ff7f0e')\n",
    "plt.errorbar(range(42), np.nanmedian(noncast, axis=0), yerr=1.96*np.nanstd(noncast)/np.sqrt(sum(np.isnan(noncast))), color='#ff7f0e')\n",
    "plt.vlines([9,25, 31], ymin=100, ymax=max(np.nanmedian(noncast, axis=0))+45, colors='r', alpha=0.3, linewidth=10)\n",
    "plt.legend(['CAST', '129'])\n",
    "fig.savefig(post_analysis_folder+os.sep+'distance_geom_center.pdf',bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+os.sep+'distance_geom_center.png',bbox_inches='tight')\n",
    "fig.savefig(post_analysis_folder+os.sep+'distance_geom_center.svg',bbox_inches='tight')\n",
    "# save plot data.\n",
    "np.save(analysis_folder+os.sep+r'cast_geom_distance_median.npy', np.nanmedian(cast, axis=0))\n",
    "np.save(analysis_folder+os.sep+r'129_geom_distance_median.npy', np.nanmedian(noncast, axis=0))\n",
    "np.save(analysis_folder+os.sep+r'cast_geom_distance_errors.npy', 1.96*np.nanstd(cast)/np.sqrt(sum(np.isnan(cast))))\n",
    "np.save(analysis_folder+os.sep+r'129_geom_distance_errors.npy', 1.96*np.nanstd(noncast)/np.sqrt(sum(np.isnan(noncast))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
