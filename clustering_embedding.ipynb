{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0bdf00",
   "metadata": {},
   "source": [
    "<h2> Scripts for clustering chromsome structures from chromatin tracing <h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491fe338",
   "metadata": {},
   "source": [
    "<h4> Import packages for scripts </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "import h5py\n",
    "import snapatac2 as snap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(r'/path/to/CommonTools')\n",
    "\n",
    "import PipelineFunctions as pipeline\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.spatial.distance import squareform,pdist,cdist\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dimension reduction and clustering libraries\n",
    "import umap\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['font.size'] = 15\n",
    "matplotlib.rcParams['font.family']='Arial'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff161147",
   "metadata": {},
   "source": [
    "<h4> Default processing to convert into h5ad for SnapATAC2 </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca087f3f-cf46-4cf8-bb54-93ceddb76378",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here, we are taking in linearly interpolated (no nan values allowed) pairwise distance vectors for each trace \n",
    "(interpolated_and_linearized_pairwise_traces.npy). Each trace need to be the same length, ordered in the same way. In addition, we want to\n",
    "have a list of identifiers for the traces which I later load in and call categories. This list contains a concatenation of \n",
    "allele ID \"CAST\" or \"129\" and the experiment ID (a number in this case, though the identifier doesn't matter too much.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy = np.load('/path/to/interpolated_and_linearized_pairwise_traces.npy')\n",
    "median_npy = np.nanmedian(npy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67908131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing zeros from the array, setting to median value\n",
    "for row in range(npy.shape[0]):\n",
    "    for col in range(npy.shape[1]):\n",
    "        if npy[row,col] == 0:\n",
    "            npy[row,col] = median_npy[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c4707",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ad.AnnData(npy)\n",
    "data.write('/path/to/your_name.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feff968",
   "metadata": {},
   "source": [
    "<h3> Choose the h5ad file you want to look at here as well as the save location </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e85792",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = snap.read('/path/to/your_name.h5ad', backed=None)\n",
    "categories = np.load('/path/to/category_file.npy')\n",
    "cluster_folder = '/path/to/save/folder'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739cc042-f823-4fdf-9059-854b1da2d81a",
   "metadata": {},
   "source": [
    "<h4>Start running SnapATAC2 from feature selection, PCA, etc</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "snap.pp.select_features(data, n_features=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28562e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data.X = sparse.csr_matrix(data.X)\n",
    "snap.tl.spectral(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "snap.pl.spectral_eigenvalues(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca7fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aab788",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "snap.tl.umap(data, n_comps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb779d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "snap.pp.knn(data)\n",
    "snap.tl.leiden(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd08bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_labels = [ x.replace(\"129\",\"\") for x in categories ]\n",
    "experiment_labels = [ x.replace(\"cast\",\"\") for x in experiment_labels ]\n",
    "data.obs['experiment'] = experiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2463e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We saved all alleles in order with CAST first, then 129, so this was a straightforward way to handle this\n",
    "data.obs['allele'] = 1*np.array([ '129' in categories[i] for i in range(len(categories)) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e84ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.obs['experiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48826718",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "savefile = cluster_folder+os.sep+r'allele_labels_umap.png'\n",
    "snap.pl.umap(data, color='log_gyr',\n",
    "             interactive=True, height=800, width=1000, marker_size=4, show=True, use_rep='X_spectral')\n",
    "                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51616910",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "savefile = cluster_folder+os.sep+r'allele_labels_umap.png'\n",
    "snap.pl.umap(data, color='allele',\n",
    "             interactive=False, height=1600, width=2000, marker_size=5, show=True, out_file=savefile)\n",
    "                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0a382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "savefile = cluster_folder+os.sep+r'leiden_labels_umap.png'\n",
    "snap.pl.umap(data, color='leiden',\n",
    "             interactive=True, height=800, width=1000, marker_size=3, show=True, out_file=savefile)\n",
    "                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb4dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "savefile = cluster_folder+os.sep+r'experiment_labels_umap.png'\n",
    "snap.pl.umap(data, color='experiment',\n",
    "             interactive=True, height=800, width=1000, marker_size=4, out_file=savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbdad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "savefile = cluster_folder+os.sep+r'rad_gyr_labels_umap.png'\n",
    "snap.pl.umap(data, color='rad_gyr',\n",
    "             interactive=False, height=1600, width=2000, marker_size=10, out_file=savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "savefile = cluster_folder+os.sep+r'log_rad_gyr_labels_umap.png'\n",
    "snap.pl.umap(data, color='log_gyr',\n",
    "             interactive=False, height=1600, width=2000, marker_size=10, out_file=savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4349ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixellated_umap_by_expt(anndata, num_pixels=100):\n",
    "    \n",
    "    def myround(x, base=5):\n",
    "        return base * round(x/base)\n",
    "    \n",
    "    # grab umap coordinates and labels\n",
    "    umap_coords = anndata.obsm['X_umap']\n",
    "    umap_experiment_labels_allele = anndata.obs['experiment']\n",
    "    \n",
    "    umap_experiment_labels = [ x.replace(\"129\",\"\") for x in anndata.obs['experiment'] ]\n",
    "    umap_experiment_labels = [ x.replace(\"cast\",\"\") for x in umap_experiment_labels ]\n",
    "    \n",
    "    experiment_counts = {}\n",
    "    \n",
    "    # make a dictionary to normalize the counts by experiment total representation\n",
    "    uniq_expts, expt_cts = np.unique(umap_experiment_labels, return_counts=True)\n",
    "    for i in range(len(uniq_expts)):\n",
    "        experiment_counts[uniq_expts[i]] = expt_cts[i]\n",
    "    \n",
    "    print(experiment_counts)\n",
    "    \n",
    "    # find x min/max and y min/max and make them nice numbers to work with.\n",
    "    x_min = np.floor(np.amin(umap_coords[:,1]))\n",
    "    x_max = np.ceil(np.amax(umap_coords[:,1]))\n",
    "    \n",
    "    y_min = np.floor(np.amin(umap_coords[:,0]))\n",
    "    y_max = np.ceil(np.amax(umap_coords[:,0]))\n",
    "    \n",
    "    # find bin size\n",
    "    binsize_x = (x_max-x_min)/num_pixels\n",
    "    binsize_y = (y_max-y_min)/num_pixels\n",
    "    \n",
    "    # create the empty array to work with.\n",
    "    pixels = {}\n",
    "    \n",
    "    for idx, point in enumerate(umap_coords):\n",
    "\n",
    "        if np.all([x_min < point[1],point[1] <= x_max, y_min < point[0], point[0] <= y_max] ):\n",
    "            # find which index it goes in for x and y and add it to that.\n",
    "            x_bin = int((x_max-point[1])//binsize_x)\n",
    "            y_bin = int((point[0]-y_min)//binsize_y)\n",
    "\n",
    "            # add the point to its respective pixel entry.\n",
    "            key = str(x_bin)+'_'+str(y_bin)\n",
    "            if key not in pixels.keys():\n",
    "                pixels[key] = [umap_experiment_labels[idx]]\n",
    "            else:\n",
    "                pixels[key].append(umap_experiment_labels[idx])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    pixellated_matrix = np.empty((num_pixels, num_pixels))\n",
    "    pixellated_matrix[:,:] = np.nan\n",
    "    \n",
    "    for key, value in pixels.items():\n",
    "        \n",
    "        inds = [int(x) for x in key.split('_') ]\n",
    "        \n",
    "        ids, counts = np.unique(value, return_counts=True)\n",
    "        \n",
    "        normalized_counts = [ counts[i]/experiment_counts[ids[i]] for i in range(len(ids)) ]\n",
    "        dominant_cluster = list(normalized_counts).index(max(normalized_counts))\n",
    "        \n",
    "        pixellated_matrix[inds[0], inds[1]] = dominant_cluster\n",
    "    \n",
    "    return pixellated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c5eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixellated_umap_by_log_gyr(anndata, num_pixels=100):\n",
    "    \n",
    "    def myround(x, base=5):\n",
    "        return base * round(x/base)\n",
    "    \n",
    "    # grab umap coordinates and labels\n",
    "    umap_coords = anndata.obsm['X_umap']\n",
    "    umap_experiment_labels_allele = anndata.obs['experiment']\n",
    "    \n",
    "    umap_experiment_labels = [ x.replace(\"129\",\"\") for x in anndata.obs['experiment'] ]\n",
    "    umap_experiment_labels = [ x.replace(\"cast\",\"\") for x in umap_experiment_labels ]\n",
    "    \n",
    "    experiment_counts = {}\n",
    "    \n",
    "    # make a dictionary to normalize the counts by experiment total representation\n",
    "    uniq_expts, expt_cts = np.unique(umap_experiment_labels, return_counts=True)\n",
    "    for i in range(len(uniq_expts)):\n",
    "        experiment_counts[uniq_expts[i]] = expt_cts[i]\n",
    "    \n",
    "    print(experiment_counts)\n",
    "    \n",
    "    # find x min/max and y min/max and make them nice numbers to work with.\n",
    "    x_min = np.floor(np.amin(umap_coords[:,1]))\n",
    "    x_max = np.ceil(np.amax(umap_coords[:,1]))\n",
    "    \n",
    "    y_min = np.floor(np.amin(umap_coords[:,0]))\n",
    "    y_max = np.ceil(np.amax(umap_coords[:,0]))\n",
    "    \n",
    "    # find bin size\n",
    "    binsize_x = (x_max-x_min)/num_pixels\n",
    "    binsize_y = (y_max-y_min)/num_pixels\n",
    "    \n",
    "    # create the empty array to work with.\n",
    "    pixels = {}\n",
    "    \n",
    "    for idx, point in enumerate(umap_coords):\n",
    "\n",
    "        if np.all([x_min < point[1],point[1] <= x_max, y_min < point[0], point[0] <= y_max] ):\n",
    "            # find which index it goes in for x and y and add it to that.\n",
    "            x_bin = int((x_max-point[1])//binsize_x)\n",
    "            y_bin = int((point[0]-y_min)//binsize_y)\n",
    "\n",
    "            # add the point to its respective pixel entry.\n",
    "            key = str(x_bin)+'_'+str(y_bin)\n",
    "            if key not in pixels.keys():\n",
    "                pixels[key] = [anndata.obs['log_gyr'][idx]]\n",
    "            else:\n",
    "                pixels[key].append(anndata.obs['log_gyr'][idx])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    pixellated_matrix = np.empty((num_pixels, num_pixels))\n",
    "    pixellated_matrix[:,:] = np.nan\n",
    "    \n",
    "    for key, value in pixels.items():\n",
    "        \n",
    "        inds = [int(x) for x in key.split('_') ]\n",
    "        \n",
    "        average = np.nanmedian(value)\n",
    "        \n",
    "        pixellated_matrix[inds[0], inds[1]] = average\n",
    "    \n",
    "    return pixellated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixellated_umap_by_rad_gyr(anndata, num_pixels=100):\n",
    "    \n",
    "    def myround(x, base=5):\n",
    "        return base * round(x/base)\n",
    "    \n",
    "    # grab umap coordinates and labels\n",
    "    umap_coords = anndata.obsm['X_umap']\n",
    "    umap_experiment_labels_allele = anndata.obs['experiment']\n",
    "    \n",
    "    umap_experiment_labels = [ x.replace(\"129\",\"\") for x in anndata.obs['experiment'] ]\n",
    "    umap_experiment_labels = [ x.replace(\"cast\",\"\") for x in umap_experiment_labels ]\n",
    "    \n",
    "    experiment_counts = {}\n",
    "    \n",
    "    # make a dictionary to normalize the counts by experiment total representation\n",
    "    uniq_expts, expt_cts = np.unique(umap_experiment_labels, return_counts=True)\n",
    "    for i in range(len(uniq_expts)):\n",
    "        experiment_counts[uniq_expts[i]] = expt_cts[i]\n",
    "    \n",
    "    print(experiment_counts)\n",
    "    \n",
    "    # find x min/max and y min/max and make them nice numbers to work with.\n",
    "    x_min = np.floor(np.amin(umap_coords[:,1]))\n",
    "    x_max = np.ceil(np.amax(umap_coords[:,1]))\n",
    "    \n",
    "    y_min = np.floor(np.amin(umap_coords[:,0]))\n",
    "    y_max = np.ceil(np.amax(umap_coords[:,0]))\n",
    "    \n",
    "    # find bin size\n",
    "    binsize_x = (x_max-x_min)/num_pixels\n",
    "    binsize_y = (y_max-y_min)/num_pixels\n",
    "    \n",
    "    # create the empty array to work with.\n",
    "    pixels = {}\n",
    "    \n",
    "    for idx, point in enumerate(umap_coords):\n",
    "\n",
    "        if np.all([x_min < point[1],point[1] <= x_max, y_min < point[0], point[0] <= y_max] ):\n",
    "            # find which index it goes in for x and y and add it to that.\n",
    "            x_bin = int((x_max-point[1])//binsize_x)\n",
    "            y_bin = int((point[0]-y_min)//binsize_y)\n",
    "\n",
    "            # add the point to its respective pixel entry.\n",
    "            key = str(x_bin)+'_'+str(y_bin)\n",
    "            if key not in pixels.keys():\n",
    "                pixels[key] = [anndata.obs['rad_gyr'][idx]]\n",
    "            else:\n",
    "                pixels[key].append(anndata.obs['rad_gyr'][idx])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    pixellated_matrix = np.empty((num_pixels, num_pixels))\n",
    "    pixellated_matrix[:,:] = np.nan\n",
    "    \n",
    "    for key, value in pixels.items():\n",
    "        \n",
    "        inds = [int(x) for x in key.split('_') ]\n",
    "        \n",
    "        average = np.nanmedian(value)\n",
    "        \n",
    "        pixellated_matrix[inds[0], inds[1]] = average\n",
    "    \n",
    "    return pixellated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixellated_umap_by_allele(anndata, num_pixels=100):\n",
    "    \n",
    "    def myround(x, base=5):\n",
    "        return base * round(x/base)\n",
    "    \n",
    "    # grab umap coordinates and labels\n",
    "    umap_coords = anndata.obsm['X_umap']\n",
    "    umap_allele_labels = anndata.obs['allele']\n",
    "    \n",
    "    allele_counts = {}\n",
    "    \n",
    "    # make a dictionary to normalize the counts by experiment total representation\n",
    "    uniq_alleles, allele_cts = np.unique(umap_allele_labels, return_counts=True)\n",
    "    for i in range(len(uniq_alleles)):\n",
    "        allele_counts[uniq_alleles[i]] = allele_cts[i]\n",
    "    \n",
    "    print(allele_counts)\n",
    "    \n",
    "    # find x min/max and y min/max and make them nice numbers to work with.\n",
    "    x_min = np.floor(np.amin(umap_coords[:,1]))\n",
    "    x_max = np.ceil(np.amax(umap_coords[:,1]))\n",
    "    \n",
    "    y_min = np.floor(np.amin(umap_coords[:,0]))\n",
    "    y_max = np.ceil(np.amax(umap_coords[:,0]))\n",
    "    \n",
    "    # find bin size\n",
    "    binsize_x = (x_max-x_min)/num_pixels\n",
    "    binsize_y = (y_max-y_min)/num_pixels\n",
    "    \n",
    "    # create the empty array to work with.\n",
    "    pixels = {}\n",
    "    \n",
    "    for idx, point in enumerate(umap_coords):\n",
    "\n",
    "        if np.all([x_min < point[1],point[1] <= x_max, y_min < point[0], point[0] <= y_max] ):\n",
    "            # find which index it goes in for x and y and add it to that.\n",
    "            x_bin = int((x_max-point[1])//binsize_x)\n",
    "            y_bin = int((point[0]-y_min)//binsize_y)\n",
    "\n",
    "            # add the point to its respective pixel entry.\n",
    "            key = str(x_bin)+'_'+str(y_bin)\n",
    "            if key not in pixels.keys():\n",
    "                pixels[key] = [umap_allele_labels[idx]]\n",
    "            else:\n",
    "                pixels[key].append(umap_allele_labels[idx])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    pixellated_matrix = np.empty((num_pixels, num_pixels))\n",
    "    pixellated_matrix[:,:] = np.nan\n",
    "    \n",
    "    for key, value in pixels.items():\n",
    "        \n",
    "        inds = [int(x) for x in key.split('_') ]\n",
    "        \n",
    "        ids, counts = np.unique(value, return_counts=True)\n",
    "        \n",
    "        # check if we have both, neither, or only one allele in that box.\n",
    "        if len(counts) > 1:\n",
    "            pixellated_matrix[inds[0], inds[1]] = (counts[0]-counts[1])\n",
    "        elif len(counts) == 0:\n",
    "            pixellated_matrix[inds[0], inds[1]] = 0\n",
    "        else:\n",
    "            # if we only have one, check if it is a 0 or a 1. (CAST is 0, 129 is 1)\n",
    "            if ids[0] == '0':\n",
    "                pixellated_matrix[inds[0], inds[1]] = counts[0]\n",
    "            elif ids[0] == '1':\n",
    "                pixellated_matrix[inds[0], inds[1]] = -counts[0]\n",
    "\n",
    "\n",
    "    ############ CAST domninant is positive, 129 dominant is negative\n",
    "    return pixellated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "matrix = pixellated_umap_by_rad_gyr(data)\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(matrix, cmap='Reds')\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.axis('on')\n",
    "# Hide X and Y axes label marks\n",
    "ax.xaxis.set_tick_params(labelbottom=False)\n",
    "ax.yaxis.set_tick_params(labelleft=False)\n",
    "\n",
    "# Hide X and Y axes tick marks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.savefig(cluster_folder+os.sep+'rad_gyr_downsample.png', bbox_inches='tight')\n",
    "plt.savefig(cluster_folder+os.sep+'rad_gyr_downsample.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f03092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "matrix = pixellated_umap_by_log_gyr(data, 30)\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(matrix, cmap='magma_r')\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.axis('on')\n",
    "# Hide X and Y axes label marks\n",
    "ax.xaxis.set_tick_params(labelbottom=False)\n",
    "ax.yaxis.set_tick_params(labelleft=False)\n",
    "\n",
    "# Hide X and Y axes tick marks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.savefig(cluster_folder+os.sep+'log_rad_gyr_downsample.png', bbox_inches='tight')\n",
    "plt.savefig(cluster_folder+os.sep+'log_rad_gyr_downsample.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a105e83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "matrix = pixellated_umap_by_allele(data, 50)\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(matrix, cmap='seismic')\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.axis('on')\n",
    "# Hide X and Y axes label marks\n",
    "ax.xaxis.set_tick_params(labelbottom=False)\n",
    "ax.yaxis.set_tick_params(labelleft=False)\n",
    "\n",
    "# Hide X and Y axes tick marks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.savefig(cluster_folder+os.sep+'dominant_allele_downsample.png', bbox_inches='tight')\n",
    "plt.savefig(cluster_folder+os.sep+'dominant_allele_downsample.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda49c80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "matrix = pixellated_umap_by_expt(data)\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(matrix, cmap='tab20b')\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.axis('on')\n",
    "# Hide X and Y axes label marks\n",
    "ax.xaxis.set_tick_params(labelbottom=False)\n",
    "ax.yaxis.set_tick_params(labelleft=False)\n",
    "\n",
    "# Hide X and Y axes tick marks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.savefig(cluster_folder+os.sep+'dominant_cluster_downsample.png', bbox_inches='tight')\n",
    "plt.savefig(cluster_folder+os.sep+'dominant_cluster_downsample.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5fa9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixellated_umap_by_single_expt(anndata, experiment_num, num_pixels=100):\n",
    "    \n",
    "    def myround(x, base=5):\n",
    "        return base * round(x/base)\n",
    "    \n",
    "    # grab umap coordinates and labels\n",
    "    umap_coords = anndata.obsm['X_umap']\n",
    "    umap_experiment_labels_allele = anndata.obs['experiment']\n",
    "    \n",
    "    umap_experiment_labels = [ x.replace(\"129\",\"\") for x in anndata.obs['experiment'] ]\n",
    "    umap_experiment_labels = [ x.replace(\"cast\",\"\") for x in umap_experiment_labels ]\n",
    "    \n",
    "    experiment_counts = {}\n",
    "    \n",
    "    # make a dictionary to normalize the counts by experiment total representation\n",
    "    uniq_expts, expt_cts = np.unique(umap_experiment_labels, return_counts=True)\n",
    "    for i in range(len(uniq_expts)):\n",
    "        experiment_counts[uniq_expts[i]] = expt_cts[i]\n",
    "    \n",
    "    print(experiment_counts)\n",
    "    \n",
    "    # find x min/max and y min/max and make them nice numbers to work with.\n",
    "    x_min = np.floor(np.amin(umap_coords[:,1]))\n",
    "    x_max = np.ceil(np.amax(umap_coords[:,1]))\n",
    "    \n",
    "    y_min = np.floor(np.amin(umap_coords[:,0]))\n",
    "    y_max = np.ceil(np.amax(umap_coords[:,0]))\n",
    "    \n",
    "    # find bin size\n",
    "    binsize_x = (x_max-x_min)/num_pixels\n",
    "    binsize_y = (y_max-y_min)/num_pixels\n",
    "    \n",
    "    # create the empty array to work with.\n",
    "    pixels = {}\n",
    "    \n",
    "    for idx, point in enumerate(umap_coords):\n",
    "\n",
    "        if np.all([x_min < point[1],point[1] <= x_max, y_min < point[0], point[0] <= y_max] ):\n",
    "            # find which index it goes in for x and y and add it to that.\n",
    "            x_bin = int((x_max-point[1])//binsize_x)\n",
    "            y_bin = int((point[0]-y_min)//binsize_y)\n",
    "\n",
    "            # add the point to its respective pixel entry.\n",
    "            key = str(x_bin)+'_'+str(y_bin)\n",
    "            if key not in pixels.keys():\n",
    "                pixels[key] = [umap_experiment_labels[idx]]\n",
    "            else:\n",
    "                pixels[key].append(umap_experiment_labels[idx])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    pixellated_matrix = np.empty((num_pixels, num_pixels))\n",
    "    pixellated_matrix[:,:] = np.nan\n",
    "    \n",
    "    for key, value in pixels.items():\n",
    "        \n",
    "        inds = [int(x) for x in key.split('_') ]\n",
    "        \n",
    "        count = sum([ v == experiment_num for v in value ])/experiment_counts[experiment_num]\n",
    "        \n",
    "        pixellated_matrix[inds[0], inds[1]] = count\n",
    "    \n",
    "    return pixellated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a53a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for e in np.unique(data.obs['experiment']):\n",
    "    matrix = pixellated_umap_by_single_expt(data, e, 30)\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.heatmap(matrix, cmap='Reds')\n",
    "    ax = plt.gca()\n",
    "\n",
    "    plt.axis('on')\n",
    "    # Hide X and Y axes label marks\n",
    "    ax.xaxis.set_tick_params(labelbottom=False)\n",
    "    ax.yaxis.set_tick_params(labelleft=False)\n",
    "\n",
    "    # Hide X and Y axes tick marks\n",
    "    plt.title(\"Downsampled distribution of chromosomes for Experiment \"+e)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.savefig(cluster_folder+os.sep+'cluster_'+e+'downsample.png', bbox_inches='tight')\n",
    "    plt.savefig(cluster_folder+os.sep+'cluster_'+e+'downsample.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
